{"cells":[{"cell_type":"markdown","source":"# Generación de Melodías\n\nEste notebook está dedicado a programar el código necesario para llevar a cabo el proyecto apoyándose en las herramientas del otro notebook. Para esto, se crea una clase llamada MelodyGenerator, que almacena un modelo de Markov (a elegir entre una cadena simple y un HMM) y métodos para recolectar datos de entrenamiento, entrenar dicho modelo y utilizar el resultado para generar melodías.\n\n*Por:*\n- Sebastián Toloza\n- Benjamín Valdés Vera\n\nBloque de instalación e importación:","metadata":{"tags":[],"cell_id":"34f5cf8866b448ab9d8a32ae01f7ee19","source_hash":"2706fb42","is_code_hidden":true,"execution_start":1669301136771,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import os\nimport mido\nfrom algoritmos import *","metadata":{"tags":[],"cell_id":"1e14eab77e2945dab488d36174b4aeee","source_hash":"7e6ce368","execution_start":1671495780057,"execution_millis":501,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Clase MelodyGenerator\n\nEsta clase es una interface con las dos clases detalladas en AlgoritmosHMM. Se encarga del procesamiento MIDI y de llamar apropiadamente a los métodos de ambas clases para generar una melodía según data de entrenamiento previamente seleccionada de tracks MIDI.","metadata":{"tags":[],"cell_id":"05b06b5e25a0474f8a81b2248d75cea2","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"class MelodyGenerator:\n    \"\"\"MelodyGenerator: Clase que intermedia entre el estandar MIDI y los modelos prrogramados.\n    Puede contener un HMM o un OMM a especificar.\"\"\"\n    def __init__(self, model_type, hidden_states):\n        \"\"\"Recibe el tipo de modelo deseado y la cantidad de estados ocultos (solo usada en HMM).\n        Crea una instancia MelodyGenerator sin data de entenamiento aún\"\"\"\n        assert model_type in [\"HMM\", \"OMM\"], f\"El tipo del modelo dado debe ser HMM o bien OMM, recibí {model_type}\"\n        self.model_type = model_type\n        self.hidden_states = hidden_states\n        self.model = None\n        self.training_data = None\n\n        # Unidades de traducción:\n        Notas = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n        self.midi_to_note = {n: Notas[n%12] + str((n//12) - 1) for n in range(128)}\n        print(f\"Modelo de tipo {self.model_type} creado exitosamente.\")\n    \n    def load_training_data(self, folder=\"DPPt\"):\n        \"\"\"Corre un bucle de interacción con el usuario para especificar las melodías a ser usadas\n        durante el entrenamiento del modelo. Al final, crea el modelo al haber definido la cantidad\n        de osbservables.\"\"\"\n        # Bucle de las melodías de entrenamiento\n        L = []\n        ready = False\n        while not ready:\n            # Bucle para pedir nombre válido de una canción\n            name_is_valid = False\n            while not name_is_valid:\n                name = input(\"Ingrese nombre del archivo MIDI (ejemplo 'Item.mid'):\\n\")\n                name_is_valid = os.path.join(name) in os.listdir(folder)\n                if not name_is_valid:\n                    print(\"Archivo no encontrado.\")\n            mid = mido.MidiFile(f\"{folder}/{name}\", clip=True)\n            num_tracks = len(mid.tracks)\n\n            # Bucle para pedir número válido de track mostrando previews\n            user_has_decided = False\n            while not user_has_decided:\n                track_is_valid = False\n                while not track_is_valid:\n                    idx = int(input(f\"El archivo seleccionado posee {num_tracks} tracks. Elija el índice del que quiere extraer:\\n\"))\n                    track_is_valid = idx in range(num_tracks)\n                    if not track_is_valid:\n                        print(\"Track inválido\")\n                track = mid.tracks[idx]\n                sample = [self.midi_to_note[m.note] for m in track if (m.type == 'note_on' and m.velocity != 0)]\n                print(sample[:10])\n                user_has_decided = input(\"Estas son las primeras 10 notas del track seleccionado ¿Mantiene su selección? [y/n]\\n\") == 'y'\n\n            # Bucle para pedir transposición\n            transpose_is_valid = False\n            while not transpose_is_valid:\n                transpose = input(\"¿Desea transponer la melodía extraída? Ingrese un número de semitonos\\npor tranponer hacia arriba\\nSi no desea transponer, ingrese 0:\\n\")\n                transpose_is_valid = transpose.isnumeric()\n            transpose = int(transpose)\n\n            # Aplicamos transposición\n            for m in track:\n                if m.type == 'note_on':\n                    m.note += transpose\n            \n            L += track\n            ready = input(\"¿Desea continuar añadiendo melodías a la data de entrenamiento? [y/n]\\n\") == 'n'\n\n        # Incorporamos una lista con los valores MIDI de las notas\n        # PENDIENTE: En el estado actual nos estamos olvidando de los ritmos\n        Notas_midi = []\n        for m in L:\n            if m.type == 'note_on' and m.velocity != 0:\n                Notas_midi.append(m.note)\n        \n        Notas_u = []\n        for n in Notas_midi:\n            if n not in Notas_u:\n                Notas_u.append(n)\n        Notas_u.sort()\n        \n        self.index_to_midi = {j: Notas_u[j] for j in range(len(Notas_u))}\n        self.midi_to_index = {v: k for k, v in self.index_to_midi.items()}\n        Notas_idx = [self.midi_to_index[nota] for nota in Notas_midi]\n        self.training_data = np.array(Notas_idx)\n\n        # Creamos el modelo\n        if self.model_type == \"HMM\":  # Si es HMM, uso los estados ocultos y las notas como observables.\n            N = self.hidden_states\n            M = len(Notas_u)\n            self.model = HMM(N, M)\n        else:  # Si es OMM, las notas mismas son los estados\n            N = len(Notas_u)\n            self.model = OMM(N)\n\n        print(\"Proceso de carga de data de entrenamiento finalizado.\")\n\n    def train(self, verbose=False):\n        \"\"\"Llama al método de entrenamiento de su correspondiente modeo, pidiendo información\n        adicional si es necesario.\"\"\"\n        assert self.model is not None, \"Cargue data de entrenamiento antes de entrenar.\"\n        if self.model.__class__.__name__ == \"HMM\":\n            eps = float(input(\"Entrenando un HMM. Ingrese el grado de tolerancia para medir la convergencia:\\n\"))\n            num = int(input(\"Ingrese el número máximo de iteraciones:\\n\"))\n            self.model.train(self.training_data, eps, num, verbose)\n        elif self.model.__class__.__name__ == \"OMM\":\n            # Si el modelo es OMM, utilizamos el método train con la secuencia de melodías\n            self.model.train(self.training_data)\n        print(\"Entrenamiento del modelo finalizado con éxito.\")\n\n    def generate(self, steps, return_type=\"MidiFile\"):\n        \"\"\"Llama al método de simulación de su correspondiente modelo. Retorna una secuencia de\n        notas en formato de string\"\"\"\n        assert return_type in [\"MidiFile\", \"Sequence\"], f\"return_type debe ser MidiFile o Sequence. Recibí {return_type}\"\n        seq_idx = self.model.simulate(steps)\n        seq_midi = [self.index_to_midi[idx] for idx in seq_idx]\n        if return_type == \"Sequence\":\n            seq_notes = [self.midi_to_note[mid] for mid in seq_midi]\n            print(\"Secuencia de notas generada exitosamente.\")\n            return seq_notes\n        \n        # Creo el archivo MIDI con un track\n        MF = mido.MidiFile()\n        MF.add_track()\n\n        # Preámbulo\n        Preamble = [\n            mido.MetaMessage('track_name', name='Piano\\x00', time=0),\n            mido.MetaMessage('time_signature', numerator=4, denominator=4, clocks_per_click=24, notated_32nd_notes_per_beat=8, time=0),\n            mido.MetaMessage('key_signature', key='C', time=0),\n            mido.MetaMessage('set_tempo', tempo=500000, time=0),\n            mido.Message('control_change', channel=0, control=121, value=0, time=0),\n            mido.Message('program_change', channel=0, program=0, time=0),\n            mido.Message('control_change', channel=0, control=7, value=100, time=0),\n            mido.Message('control_change', channel=0, control=10, value=64, time=0),\n            mido.Message('control_change', channel=0, control=91, value=0, time=0),\n            mido.Message('control_change', channel=0, control=93, value=0, time=0),\n            mido.MetaMessage('midi_port', port=0, time=0),\n        ]\n        MF.tracks[0] += Preamble\n\n        # Añadimos notas\n        msg_on = mido.Message('note_on', channel=0, note=seq_midi[0], velocity=80, time=0)\n        msg_off = mido.Message('note_off', channel=0, note=seq_midi[0], velocity=80, time=455)\n        MF.tracks[0].append(msg_on)\n        MF.tracks[0].append(msg_off)\n        for m in seq_midi[1:]:\n            msg_on = mido.Message('note_on', channel=0, note=m, velocity=80, time=25)\n            msg_off = mido.Message('note_off', channel=0, note=m, velocity=80, time=455)\n            MF.tracks[0].append(msg_on)\n            MF.tracks[0].append(msg_off)\n        # Finalizamos track\n        MF.tracks[0].append(mido.MetaMessage('end_of_track', time=1))\n        print(\"Archivo MIDI generado exitosamente.\")\n        return MF","metadata":{"tags":[],"cell_id":"a39c448436244800b779206f2289458d","source_hash":"4781744a","execution_start":1671499793077,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"## Experimentos\n\nAquí, experimentamos con el código programado para generar algunas melodías.","metadata":{"tags":[],"cell_id":"343010f9706f42059d96d1e04fbbca18","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### 1. Paseo aleatorio por la escala mayor\n\nSe utilizó la siguiente data de entrenamiento que corresponde a una escala de Do Mayor:\n\n![Picture title](img/1train.png)\n\nCon esto, se entrenó un modelo observable. La matriz de transición obtenida, por lo tanto, debería ser la de un paseo aleatorio simple. A continuación está el código para esto:","metadata":{"tags":[],"cell_id":"e95a3058f2344b93b831d90f0ea35185","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"MG = MelodyGenerator(\"OMM\", None)\nMG.load_training_data(folder=\"Experimentos\")\nMG.train()\nmid = MG.generate(49)\nmid.save(\"Escala_generado.mid\")","metadata":{"tags":[],"cell_id":"e0143ef922ce499a9afa3284af8140bd","source_hash":"37fcdbe1","execution_start":1671300602561,"execution_millis":107502,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Modelo de tipo OMM creado exitosamente.\n['C5', 'D5', 'E5', 'F5', 'G5', 'A5', 'B5', 'C6', 'B5', 'A5']\nProceso de carga de data de entrenamiento finalizado.\nEntrenamiento del modelo finalizado con éxito.\nArchivo MIDI generado exitosamente.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Tras correr este código, este es un ejemplo de melodía que se obtiene:\n\n![Picture title](img/1gen.png)\n\nNotar que efectivamente el comportamiento es el de un paseo aleatorio simple. Inspeccionando manualmente la matriz de transición, se puede confirmar esto.","metadata":{"tags":[],"cell_id":"057eb1bca30d4890ba20142ec464f618","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### 2. Route 201\n\nSe utilizan dos instrumentos del archivo Route 201.mid: la parte de flauta y la de piano:\n\n![Picture title](img/2train.png)\n\nNótese que como efecto de sonido, el archivo tiene muchas notas repetidas en ambas partes. Esto es a propósito para el OST del juego, pero podría generar una melodías que repita notas de manera poco armoniosa.\n\nSe entrena un modelo de tipo HMM con 10 estados ocultos, cantidad elegida arbitrariamente.","metadata":{"tags":[],"cell_id":"879fc9441c594927870b6d728ffce146","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"MG = MelodyGenerator(\"HMM\", 10)\nMG.load_training_data()\nMG.train(verbose=True)\nmid = MG.generate(49)\nmid.save(\"201HMM_piano.mid\")","metadata":{"tags":[],"cell_id":"15bc3ae233464254b87cba3ca22f5bc0","source_hash":"833d0a24","output_cleared":false,"execution_start":1671302947981,"execution_millis":31271,"is_output_hidden":false,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Modelo de tipo HMM creado exitosamente.\n['E5', 'D5', 'C5', 'D5', 'C5', 'G4', 'E4', 'F4', 'E4', 'F4']\nProceso de carga de data de entrenamiento finalizado.\nIteración 1 | dA = 0.12 | dB = 0.68 | dlam = 0.24\nIteración 2 | dA = 0.05 | dB = 0.08 | dlam = 0.15\nIteración 3 | dA = 0.07 | dB = 0.11 | dlam = 0.15\nIteración 4 | dA = 0.13 | dB = 0.16 | dlam = 0.12\nIteración 5 | dA = 0.27 | dB = 0.27 | dlam = 0.10\nIteración 6 | dA = 0.31 | dB = 0.34 | dlam = 0.12\nIteración 7 | dA = 0.29 | dB = 0.28 | dlam = 0.13\nIteración 8 | dA = 0.27 | dB = 0.29 | dlam = 0.13\nIteración 9 | dA = 0.20 | dB = 0.21 | dlam = 0.07\nIteración 10 | dA = 0.23 | dB = 0.19 | dlam = 0.01\nIteración 11 | dA = 0.24 | dB = 0.19 | dlam = 0.00\nIteración 12 | dA = 0.21 | dB = 0.15 | dlam = 0.00\nIteración 13 | dA = 0.19 | dB = 0.14 | dlam = 0.00\nIteración 14 | dA = 0.19 | dB = 0.17 | dlam = 0.00\nIteración 15 | dA = 0.20 | dB = 0.17 | dlam = 0.00\nIteración 16 | dA = 0.19 | dB = 0.15 | dlam = 0.00\nIteración 17 | dA = 0.18 | dB = 0.14 | dlam = 0.00\nIteración 18 | dA = 0.20 | dB = 0.15 | dlam = 0.00\nIteración 19 | dA = 0.15 | dB = 0.11 | dlam = 0.00\nIteración 20 | dA = 0.10 | dB = 0.07 | dlam = 0.00\nIteración 21 | dA = 0.07 | dB = 0.06 | dlam = 0.00\nIteración 22 | dA = 0.05 | dB = 0.04 | dlam = 0.00\nIteración 23 | dA = 0.03 | dB = 0.03 | dlam = 0.00\nIteración 24 | dA = 0.02 | dB = 0.02 | dlam = 0.00\nIteración 25 | dA = 0.01 | dB = 0.01 | dlam = 0.00\nIteración 26 | dA = 0.01 | dB = 0.02 | dlam = 0.00\nIteración 27 | dA = 0.01 | dB = 0.02 | dlam = 0.00\nIteración 28 | dA = 0.01 | dB = 0.02 | dlam = 0.00\nIteración 29 | dA = 0.01 | dB = 0.02 | dlam = 0.00\nIteración 30 | dA = 0.02 | dB = 0.03 | dlam = 0.00\nIteración 31 | dA = 0.02 | dB = 0.04 | dlam = 0.00\nIteración 32 | dA = 0.03 | dB = 0.06 | dlam = 0.00\nIteración 33 | dA = 0.03 | dB = 0.07 | dlam = 0.00\nIteración 34 | dA = 0.04 | dB = 0.07 | dlam = 0.00\nIteración 35 | dA = 0.03 | dB = 0.06 | dlam = 0.00\nIteración 36 | dA = 0.02 | dB = 0.03 | dlam = 0.00\nIteración 37 | dA = 0.01 | dB = 0.02 | dlam = 0.00\nIteración 38 | dA = 0.01 | dB = 0.01 | dlam = 0.00\nConvergencia alcanzada. El proceso termina a las 38 iteraciones\nNúmero máximo de iteraciones alcanzado.\nEntrenamiento del modelo finalizado con éxito.\nArchivo MIDI generado exitosamente.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### 3. Oreburgh City\n\nSe utiliza solo la melodía central de la canción:\n\n![Picture title](img/3train.png)\n\nCon esto, se entrena un HMM con 15 estados ocultos:","metadata":{"tags":[],"cell_id":"b909adebb59a474f94d53602c11b4960","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"MG = MelodyGenerator(\"HMM\", 15)\nMG.load_training_data(folder=\"Experimentos\")\nMG.train(verbose=True)\nmid = MG.generate(49)\nmid.save(\"Oreburgh_15.mid\")","metadata":{"tags":[],"cell_id":"37bc61eec1aa42ff835da8d033e33ed7","source_hash":"9ff80975","output_cleared":false,"execution_start":1671499849777,"execution_millis":18239,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Modelo de tipo OMM creado exitosamente.\n['C5', 'G5', 'D5', 'E5', 'F5', 'G5', 'C6', 'A5', 'G5', 'C5']\nProceso de carga de data de entrenamiento finalizado.\nEntrenamiento del modelo finalizado con éxito.\nArchivo MIDI generado exitosamente.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"Melodía generada:\n\n![Picture title](img/3gen.png)","metadata":{"tags":[],"cell_id":"066f43f6158c401b9aac3281dd891a1d","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### 4. Bach\n\nblablabla \n\n![Picture title](img/4train.png)\n\nblablabla 15 estados ocultos.\n","metadata":{"tags":[],"cell_id":"109f65e388d0403280108049035e8826","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"MG = MelodyGenerator(\"OMM\", 5)\nMG.load_training_data(folder=\"Experimentos\")\nMG.train(verbose=True)\nmid = MG.generate(100)\nmid.save(\"Bach_generado.mid\")","metadata":{"tags":[],"cell_id":"d673e122e47c4e618de1cde8d98fe282","source_hash":"7d27aaa2","output_cleared":false,"execution_start":1671499322033,"execution_millis":15555,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Modelo de tipo OMM creado exitosamente.\n['E6', 'D#6', 'E6', 'B5', 'G#5', 'B5', 'E5', 'F#5', 'E5', 'D#5']\nProceso de carga de data de entrenamiento finalizado.\nEntrenamiento del modelo finalizado con éxito.\nArchivo MIDI generado exitosamente.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=15d2711e-8488-4966-b405-4363c7f8973c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"03bd7cc19828481bb23f573697be6d11","deepnote_persisted_session":{"createdAt":"2022-12-20T01:51:34.576Z"},"deepnote_execution_queue":[]}}