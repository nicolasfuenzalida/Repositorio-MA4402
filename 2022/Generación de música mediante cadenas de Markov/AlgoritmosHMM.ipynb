{"cells":[{"cell_type":"markdown","source":"# Hidden Markov Models\n\nEste notebook es un resumen de las nociones teóricas de un modelo oculto de Markov y sus principales algoritmos.\n\n*Por:*\n- Benjamín Vera\n- Sebastián Toloza","metadata":{"tags":[],"cell_id":"10d3a568b7a04557a06ce51358bd007e","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt","metadata":{"tags":[],"cell_id":"629bdf7000564573932f58eca294d539","source_hash":"1b60f71f","execution_start":1670941741381,"execution_millis":455,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Notaciones\n\nPara un modelo de Markov simple (observable) homogeneo, tenemos las siguientes notaciones:\n- $t \\in \\mathbb{N}$: Tiempo discreto.\n- $E$: Conjunto de estados posibles. En este documento $E = \\{0, \\dots, N-1\\}$ finito.\n- $X_t \\in E$: Estado del sistema en el tiempo $t$.\n- $\\lambda_x = \\mathbb{P}(X_0 = x)$: Probabilidad del estado inicial.\n- $\\lambda = (\\lambda_x)_{x \\in E}$: Distribución inicial de la cadena.\n- $a_{x, y} = \\mathbb{P}(X_1 = y | X_0 = x) \\geq 0$: Probabilidad de transición de $x \\to y$. Se satisface\n$$\n\\forall x \\in E: \\sum_{y \\in E} a_{x, y} = 1\n$$\n- $A = (a_{x,y})_{x,y \\in E} \\in \\mathbb{R}^{N \\times N}$: Matriz estocástica de transición.\n\nAhora, para un modelo de Markov oculto homogeneo, pensamos en los $X_t$ como desconocidos y tenemos además los siguientes elementos:\n- $O$: Conjunto de observaciones posibles. En este documento $O = \\{0, \\dots, M-1\\}$ finito.\n- $V_t \\in O$: Observación del sistema en el tiempo $t$.\n- $b_{x, z} = \\mathbb{P}(V_t = z | X_t = x) \\geq 0$: Probabilidad de ver la observación $z \\in O$ dado que el estado oculto es $x \\in E$. Se satisface\n$$\n\\forall x \\in E: \\sum_{z \\in O} b_{x, z} = 1\n$$\n- $B = (b_{x, z})_{x \\in E, z \\in O} \\in \\mathbb{R}^{N \\times M}$: Matriz estocástica de observación.\n\nObservar que la existencia de la matriz $B$ implica que las probabilidades de observación son homogeneas en el tiempo.","metadata":{"tags":[],"cell_id":"6f4c06a512044e0b85c173bc270b7175","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"Antes de implementar las clases correspondientes, escribimos una función auxiliar que, recibiendo un vector de probabilidad $v$, modela una variable aleatoria que tiene la ley dada por el vector $v$:","metadata":{"tags":[],"cell_id":"ae7cb058377f4a04bbcf508aad2c4c4d","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"def randomSample(v):\n    \"\"\" Recibe un v (numpy array unidimensional) que actúa como densidad de probabilidad.\n    Retorna un índice aleatorio de v con la ley dada por sus valores\"\"\"\n    assert len(v.shape) == 1, f\"El vector dado no es unidimensional, tiene forma {v.size}\"\n    assert np.isclose(np.sum(v), 1), f\"El vector dado no está normalizado, sus coordenadas suman {np.sum(v)}\"\n    u = np.random.random()\n    j = 0\n    s = 0\n    s += v[0]\n    while s <= u:\n        j += 1\n        s += v[j]\n    return j","metadata":{"tags":[],"cell_id":"aef2b9e49f084c879553006af1c19b7b","source_hash":"444df8e5","execution_start":1671112671921,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Problemas de inferencia en CM simples\n\nTeniendo un modelo de Markov simple $X \\sim CM(\\lambda, P)$, aparte de ser capaces de generar secuencias arbitrarias de observaciones, dos preguntas de inferencia que nos interesaría responder son:\n- Dada una secuencia $(x_0, \\dots, x_T)$ ¿Qué tan probable es que el modelo la haya producido?\n- Dada una secuencia $(x_0, \\dots, x_t)$, encontrar la matriz de transición $P$ que mejor se ajusta a este comportamiento observado.\n\nA continuación, implementamos una clase con algoritmos simples que responden a estas preguntas.","metadata":{"tags":[],"cell_id":"c8bccc59bdde42fca0fc8a65ce35a2a2","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"class OMM:\n    \"\"\"Observable markov model: Clase que encapsula el comportamiento de una cadena de Markov\n    \"\"\"\n    def __init__(self, N):\n        \"\"\" Recibe un entero que será su dimensionalidad y crea un modelo\n        de Markov observable.\"\"\"\n        self.N = N  # Cantidad de estados\n\n        # Inicializamos los parámetros como uniformes\n        self.lam = (1/N)*np.ones(N)\n        self.A = (1/N)*np.ones((N, N))\n\n    def simulate(self, steps):\n        \"\"\" Recibe un número de pasos y simula esa cantidad de transiciones de la cadena.\n        Devuelve un vector de tamaño steps + 1\"\"\"\n        C = np.zeros(steps + 1)  # Inicializamos la cadena en cero\n        x = randomSample(self.lam)  # Elegir un estado de la distribución inicial\n        C[0] = x\n        for j in range(steps):\n            x = randomSample(self.A[x])  # Elegir un estado según la ley de la fila x de A\n            C[j+1] = x  # Añadirlo a la cadena\n        return C  # Devolver la cadena\n\n    def seqProb(self, seq):\n        \"\"\" Recibe una secuencia de estados observados de la cadena.\n        Retorna la probabilidad de haber observado esa secuencia de estados\"\"\"\n        assert ((0 <= seq) & (seq < self.N)).all(), \"No todos los estados dados en la secuencia son estados válidos de la cadena\"\n        p = self.lam[seq[0]]\n        for i in range(1, len(seq)):\n            p *= self.A[seq[i-1], seq[i]]\n        return p\n    \n    def train(self, seq):\n        \"\"\" Recibe una secuencia de estados observados de la cadena.\n        Actualiza self.A para que sea la matriz de transición que mejor explica el comportamiento observado.\"\"\"\n        assert ((0 <= seq) & (seq < self.N)).all(), \"No todos los estados dados en la secuencia son estados válidos de la cadena\"\n        freq = np.zeros((self.N, self.N))\n        # Recorro toda la secuencia contando las transiciones\n        for i in range(len(seq)-1):\n            freq[seq[i], seq[i+1]] += 1\n        \n        # Ahora normalizamos cada fila\n        for i in range(self.N):\n            S = np.sum(freq[i])\n            if S != 0:\n                freq[i] /= S\n        self.A = freq","metadata":{"tags":[],"cell_id":"5ff87cd420ab4d9cbe0a5574c94028b6","source_hash":"af673b0c","execution_start":1671044207742,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Problemas de inferencia en HMM\n\nPor otro lado, teniendo un modelo de Markov oculto $X \\sim HM(\\lambda, A, B)$, aparte de ser capaces de generar secuencias arbitrarias de observaciones, las tres preguntas grandes que nos interesaría responder son:\n- *Evaluación:* Dada una secuencia de observaciones $(v_0, \\dots, v_{T-1})$ ¿Qué tan probable es que el modelo la haya producido?\n- *Decodificación:* Dada una secuencia de observaciones $(v_0, \\dots, v_{T-1})$, encontrar la cadena de estados ocultos con mayor verosimilitud para haber generado esta secuencia.\n- *Aprendizaje:* Dada una secuencia de observaciones $(v_0, \\dots, v_{T-1})$, encontrar las matrices de transición y observación que mejor explican el comportamiento observado.\n\nLa primera pregunta da lugar al algoritmo Forward, la segunda da lugar al algoritmo de Viterbi y la tercera al de Baum-Welch. A continuación, damos una breve explicación de estos algoritmos.","metadata":{"tags":[],"cell_id":"a037ea48db584c678f484d2666a617e8","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Algoritmo Forward\n\nEn realidad consiste de dos algoritmos distintos que resuelven el problema de evaluación, pero solo vamos a implementar el forward en este documento para resolver ese problema.\n\nEl problema de evaluar la verosimilitud de una secuencia de observaciones se podría resolver a través de marginalizar sobre todas las secuencias posibles. Pero esa suma es del orden $O(N^T)$ en que $N$ son los estados posibles y $T$ es la longitud de la secuencia observada. Ya que esto es infactible, la solución consiste en utilizar una variable auxiliar definida como\n$$\n\\alpha_{x, t} = \\mathbb{P}(V_0 = v_0, \\dots, V_t = v_t, X_t = x)\n$$\nEs decir, $\\alpha_{x, t}$ es la probabilidad de haber producido la secuencia observada terminando en el estado $x \\in E$. Satisface las ecuaciones\n$$\n\\text{\\textbf{Base:}}\\qquad \\alpha_{x, 0} = \\mathbb{P}(V_0 = v_0, X_0 = x) = \\lambda_x \\cdot b_{x, v_0}\n$$\n$$\n\\text{\\textbf{Inductivo:}}\\qquad \\alpha_{x, t+1} = \\sum_{y \\in E} \\alpha_{y, t} a_{y, x} b_{x, v_{t+1}}\n$$\n$$\n\\text{\\textbf{Terminal:}}\\qquad \\mathbb{P}(V_0 = v_0, \\dots, V_{t-1} = v_{t-1}) = \\sum_{x \\in E} \\alpha_{x, t}\n$$\nDe modo que si implementamos $\\alpha = (\\alpha_{x, t})_{x \\in E, 0 \\leq t \\leq T-1} \\in \\mathbb{R}^{N \\times T}$, las ecuaciones base e inductiva se reducen a $\\alpha_{\\bullet, 0} = \\lambda \\odot B_{\\bullet, v_0}$ y $\\alpha_{x, t+1} = (\\alpha_{\\bullet, t}\\cdot A_{\\bullet, x}) b_{x, v_{t+1}}$ respectivamente. En que $\\odot$ denota el producto de Hadamard entre vectores.","metadata":{"tags":[],"cell_id":"99213b55066f40df841b8d2ef441ae63","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Algoritmo de Viterbi\n\nConsiste en un algoritmo que, dada unas observaciones y estados, entrega la cadena de estados con mayor verosimilitud, por lo que correspondería a la cadena óptima de estados.\n\nNotemos que esto se podría realizar generando todas las secuencias posibles de estados y calcular su verosimilitud, cosa de rescatar la mayor, pero esto claramente no es eficiente debido a que el número de secuencias es de orden exponencial, por lo que el algoritmo se basa en la programación dinámica.\n\nPara eso, introducimos la variable auxiliar \n\n$$\n\\nu_t(j) = \\max_{x_0,\\cdots,x_{t-1}} \\mathbb{P}(x_0,\\cdots,x_{t-1},v_0,\\cdots,v_t,x_t=j)\n$$\n\nEl cual corresponde a la probabilidad de que la cadena oculta esté en el estado $j$ después de ver las primeras $t$ observaciones y pasar por la secuencia más probable de estados $x_1,...,x_{T-1}$, dados los parámetros del modelo. Sin embargo, esto se puede definir recursivamente como\n\n$$\n\\nu_t(j) = \\max_{i=1}^N \\nu_{t-1}(j)a_{ij}b_j(v_t) \n$$\n\nque es lo que se calculará a continuación, guardando también una matriz que indica el origen de cada máxima verosimilitud (BP), para poder recuperar el camino más probable. Así, el algoritmo viene dado por\n\n$\\textbf{Inicialización:}$\n\n$$\n\\nu_0(j) = \\lambda_0b_j(v_0), \\hspace{3mm} BP_0(j)=-1, \\hspace{3mm} 1 \\leq j \\leq N\n$$\n\n$\\textbf{Inductivo:}$\n\n$$\n\\nu_t(j) = \\max_{i=1}^N \\nu_{t-1}(j)a_{ij}b_j(v_t), \\hspace{3mm}  1\\leq j \\leq N, 1< t \\leq T\n$$\n$$\nBP_t(j) = arg\\max_{i=1}^N \\nu_{t-1}(j)a_{ij}b_j(v_t), \\hspace{3mm} 1\\leq j \\leq N, 1< t \\leq T\n$$\n\n\n$\\textbf{Terminal:}$\n\n$$\n\\text{Mejor verosimilitud} \\hspace{3mm} P^*= \\max_{i=1, \\dots N} \\nu_{T}(i)\n$$\n\n$$\n\\text{Inicio de backtrace} \\hspace{3mm} q_{T^*} = \\text{argmax}_{i=1, \\dots, N} \\nu_T(i)\n$$","metadata":{"tags":[],"cell_id":"7a2233d25e6e436fae322715e34a32a8","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Algoritmo de Baum Welch\n\nAhora nos interesa el problema del entrenamiento, en donde, dada una secuencia de observaciones y el conjunto de los posibles estados en la cadena oculta, se tiene que determinar los parámetros $A$, $B$ y $\\lambda$ del modelo.\n\nPara poder ejecutar el algoritmo, necesitamos\n\nParámetro *forward*\n$$\n\\alpha_{x, t} = \\mathbb{P}(V_0 = v_0, \\dots, V_t = v_t, X_t = x)\n$$\n\nParámetro *backward*\n$$\n\\beta_{x, t} = \\mathbb{P}(V_{t+1} = v_{t+1}, \\dots, V_T = v_T \\mid X_t = x)\n$$\n\nParámetro *gamma* (responde a la probabilidad de estar en $x$ a tiempo $t$ conociendo todas las observaciones (pasadas y futuras))\n$$\n\\gamma_{x,t} = \\mathbb{P}(X_t =x\\mid O)\n$$\n\nY también necesitamos definir la matriz temporal de matrices\n\n$$\n\\xi_t(i,j) = \\mathbb{P}(X_t = i, X_{t+1}=j \\mid O) = \\frac{\\alpha_{i,t}a_{ij}b_j(V_{t+1})\\beta_j(V_{t+1})}{\\mathbb{P}(V\\mid (A,B,\\lambda))}\n$$\n\nque satisface\n\n$$\n\\gamma_{i,t} = \\sum_{j=1}^N \\xi_t(i,j)\n$$\n\nDe esta forma\n\n$$\n\\sum_{t=1}^{T-1} \\gamma_{i,t} = \\text{Número esperado de transiciones desde $x_i$}\n$$\n\n$$\n\\sum_{t=1}^{T-1} \\xi_{i,t} = \\text{Número esperado de transiciones de $x_i$ a $x_j$}\n$$\n\nPor lo que nos queda determinar los nuevos parámetros $(\\bar{A},\\bar{B},\\bar{\\lambda})$.\n\nEn efecto, la distribución inicial se obtiene mediante\n\n$$\n\\bar{\\lambda}_i = \\gamma_{i,0} = \\text{Frecuencia esperada en $x_i$ a tiempo $t=0$} \n$$\n\nLos coeficientes de $\\bar{A}$ vienen dados Por\n\n$$\n\\bar{a}_{ij} = \\frac{\\text{Número esperado de transiciones de $x_i$ a $x_j$}}{\\text{Número esperado de transiciones desde $x_i$}}\n$$\n\nEs decir,\n\n$$\n\\bar{a}_{ij} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i,j)}{\\sum_{t=1}^{T-1}\\gamma_{i,t}} \n$$\n\nY para $\\bar{B}$, tenemos \n\n$$\n\\bar{b}_{j,k} = \\frac{\\text{Número esperado de veces en el estado $j$ y observando $v_k$}}{\\text{Número esperado de veces en el estado $j$}}\n$$\n\nEs decir, \n\n$$\n\\bar{b}_{j,k} = \\frac{\\sum_{t=1}^T \\gamma_{i,t} 1_{O_t=v_k}}{\\sum_{t=1}^T \\gamma_{i,t}}\n$$\n\nCon lo cual de forma iterativa generamos nuevos parámetros (volviéndolos a usar en el modelo como input) hasta que estos convergan a un \"punto fijo\".","metadata":{"tags":[],"cell_id":"8c08f4ff7a1145c6ace1ddcdf41e1611","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"A continuación se implementa la clase HMM que incorpora todos estos algoritmos.","metadata":{"tags":[],"cell_id":"b86f1e5c9b384e62aabdee7c1d9c53ec","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"class HMM:\n    \"\"\" Hidden markov model: Clase que encapsula el comportamiento de una cadena oculta de Markov\"\"\"\n    def __init__(self, N, M):\n        \"\"\"Recibe el número de estados ocultos y de observables. Crea un Modelo de Markov Oculto\n        Cuyos parámetros son inicialmente distribuciones de probabilidad uniformes\"\"\"\n        self.N = N\n        self.M = M\n\n        # Inicializamos los parámetros aleatoriamente y normalizamos\n        # Para obtener matrices estocásticas.\n        self.lam = np.random.rand(self.N)\n        self.lam /= np.sum(self.lam)\n        self.A = np.random.rand(self.N, self.N)\n        self.B = np.random.rand(self.N, self.M)\n        for i in range(self.N):\n            self.A[i] /= np.sum(self.A[i])\n            self.B[i] /= np.sum(self.B[i])\n\n    def simulate(self, steps):\n        \"\"\" Recibe un número de pasos y simula esa cantidad de pasos del modelo.\n        Devuelve un vector de observaciones de tamaño steps + 1\"\"\"\n        H = np.zeros(steps + 1, dtype=np.int8)  # Inicializamos la cadena en cero\n        x = randomSample(self.lam)  # Elegir un estado de la distribución inicial\n        H[0] = x\n        for j in range(steps):\n            x = randomSample(self.A[x])  # Elegir un estado según la ley de la fila x de A\n            H[j+1] = x  # Añadirlo a la cadena\n        \n        # Genial, ahora H es una cadena de estados ocultos. Para cada uno de ellos escogemos una observación\n        O = np.zeros(steps + 1)\n        for j in range(steps + 1):\n            O[j] = randomSample(self.B[H[j]])\n        return O  # Devolver la cadena de observaciones\n\n    def forward(self, obs):  \n        \"\"\" Recibe una secuencia de estados observables de la cadena.\n        Retorna la verosimilitud de esa secuencia con los parámetros de la cadena\n        Implementando el algoritmo Forward\"\"\"\n        assert ((obs >= 0) & (obs < self.M)).all(), \"Las observaciones dadas no son válidas\"\n        T = len(obs)\n        # Creamos matriz forward de tamaño MxN \n        ForwardMatrix = np.zeros((self.N, T))\n        # Inicializamos la matriz \n        ForwardMatrix[:,0] = self.lam * self.B[:,obs[0]]\n        # Trabajamos recursión    \n        for t in range(1,T):\n            ForwardMatrix[:, t] = ((self.A * self.B[:, obs[t]]).T).dot(ForwardMatrix[:, t-1])\n        # Entregamos la verosimilitud de la observación        \n        return np.sum(ForwardMatrix[:,T-1]), ForwardMatrix\n    \n    def viterbi(self, obs, states):\n        ''' Recibe observaciones y estados, y entrega la cadena óptima de estados (es decir, en el \n        sentido de ser el camino más probable)'''\n        T = len(obs)\n        ViterbiMatrix = np.zeros([self.N,T])\n        Backpointer = np.zeros([self.N,T])\n        for s in range(self.N):\n            ViterbiMatrix[s,0] =  lam[s]*self.B[s,obs[0]]\n            Backpointer[s,0] = -1 # Estado inicial corresponde a distribución inicial \n            # -1 dado que el 0 confunde con el primer estado posible de la cadena \n        for t in range(1,T):\n            for s in range(self.N):\n                maxVit = []\n                for i in range(self.N):\n                    maxVit.append(ViterbiMatrix[i,t-1]*self.A[i,s]*self.B[s,obs[t]])   \n                ViterbiMatrix[s,t] = max(maxVit)     \n                Backpointer[s,t] = np.argmax(maxVit)\n        VitFinal = ViterbiMatrix[:,T-1]   \n        BestPathProb = max(VitFinal)     \n        BestPathPointer = np.argmax(VitFinal)\n        # Falta reconstruir camino óptimo de estados\n        Camino = np.append(Backpointer[BestPathPointer],BestPathPointer)\n        CaminoEstados = []\n        for i in Camino:\n            if i==-1:\n                CaminoEstados.append('Origen')\n            else:\n                CaminoEstados.append(states[int(i)])                        \n        return BestPathProb, CaminoEstados\n    \n    def backward(self,obs):\n        T = len(obs)\n        Beta = np.zeros([self.N,T])\n        for i in range(self.N):\n            Beta[i,T-1] = 1  \n        for t in reversed(range(T-1)):\n            for i in range(self.N):\n                Beta[i,t] = 0\n                for j in range(self.N):\n                    Beta[i,t] = Beta[i,t] + self.A[i,j]*self.B[j,obs[t+1]]*Beta[j,t+1]\n        P = 0\n        for j in range(self.N):\n            P = P + self.lam[j]*self.B[j,obs[0]]*Beta[0,j]\n        return P, Beta\n\n    def baumwelch(self, obs):\n        ''' Realiza 1 iteración del algoritmo de Baum Welch, encontrando matrices A_bar y B_bar\n        para el entrenamiento del modelo'''\n        T = len(obs)\n\n        A_bar = np.zeros([self.N,self.N])\n        B_bar = np.zeros([self.N,self.M])\n        lam_bar = np.zeros([self.N])\n\n        # Definimos matrices alfa y beta según lo anterior\n\n        Alfa = self.forward(obs)[1]\n        Beta = self.backward(obs)[1]\n        \n        # Creamos Xi_t(i,j)\n\n        Xi = []\n        for i in range(T-1):\n            Xi.append(np.zeros([self.N,self.N]))\n        for t in range(T-1):\n            for j in range(self.N):\n                for i in range(self.N):\n                    P = 0\n                    for s in range(self.N):\n                        P = P + Alfa[s,t]*Beta[s,t]      \n                    Xi[t][i,j] = (Alfa[i,t]*self.A[i,j]*self.B[j,obs[t+1]]*Beta[j,t+1])/P        \n\n        # Cálculo de A_bar\n\n        # Numerador\n        for j in range(self.N):\n            for i in range(self.N):\n                Xi_sum = sum(Xi)\n                A_bar[i,j] = Xi_sum[i,j]\n\n        # Denominador\n        for j in range(self.N):\n            for i in range(self.N):\n                Den = 0\n                for t in range(T-1):\n                    Den = Den + sum(Xi[t][i])\n                A_bar[i,j] = A_bar[i,j]/Den    \n\n        # Cálculo de B_bar y lam_bar\n\n        Gamma = np.zeros([self.N,T])\n\n        for t in range(T):\n            for j in range(self.N):\n                P = 0\n                for s in range(self.N):\n                    P = P + Alfa[s,t]*Beta[s,t] \n                Gamma[j,t] = Alfa[j,t]*Beta[j,t]/P        \n\n        for k in range(self.M):\n            for j in range(self.N):\n                S1 = 0\n                S2 = 0\n                for t in range(T):\n                    if obs[t] == k:\n                        S1 = S1 + Gamma[j,t]\n                    S2 = S2 + Gamma[j,t]\n                B_bar[j,k] = S1/S2 \n\n        for i in range(self.N):\n            lam_bar[i] = Gamma[i,0]\n\n        # Actualizamos los atributos del modelo con los valores nuevos\n        self.A = A_bar\n        self.B = B_bar\n        self.lam = lam_bar\n\n    def train(self, seq, eps, num, verbose=False):\n        \"\"\" Recibe una secuencia de observaciones de la cadena, un grado de tolerancia y un número\n        máximo de iteraciones. Itera el algoritmo de B-W hasta que o bien la distancia entre las tres\n        matrices sucesivas es menor a {eps}, o bien se ha alcanzado el número máximo de iteraciones {num}.\"\"\"\n        counter = 0\n        while counter < num:\n            counter += 1\n\n            lam_0 = np.copy(self.lam)\n            A_0 = np.copy(self.A)\n            B_0 = np.copy(self.B)\n\n            self.baumwelch(seq)\n\n            lam_1 = self.lam\n            A_1 = self.A\n            B_1 = self.B\n\n            dA = np.linalg.norm(A_1 - A_0, ord='fro')\n            dB = np.linalg.norm(B_1 - B_0, ord='fro')\n            dlam = np.linalg.norm(lam_1 - lam_0, ord=2)\n            if verbose:\n                print(f\"Iteración {counter} | dA = {dA:.2f} | dB = {dB:.2f} | dlam = {dlam:.2f}\")\n\n            if max([dA, dB, dlam]) < eps:\n                if verbose:\n                    print(f\"Convergencia alcanzada. El proceso termina a las {counter} iteraciones\")\n                break\n        \n        print(\"Número máximo de iteraciones alcanzado.\")\n\n","metadata":{"tags":[],"cell_id":"76256cf6485e45f6bb8d7bada4d16331","source_hash":"68bd3d2f","execution_start":1670970707492,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing\n\nA continuación, se dejan bloques de código que han sido útiles durante el proceso de implementación de los algoritmos de HMM.","metadata":{"tags":[],"cell_id":"6a505e5dc0304fb18bda1669b18ee6f1","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"# Ejemplo \nA = np.array([[0.6,0.4],[0.5, 0.5]])\nB = np.array([[0.2,0.4,0.4],[0.5,0.4,0.1]])\nlam = np.array([0.8,0.2])\n\nModelo = HMM(lam, A, B)","metadata":{"tags":[],"cell_id":"848e2cf0301e4de98510ce1f09774c09","source_hash":"4183be50","execution_start":1670941741875,"execution_millis":6,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Modelo.viterbi(np.array([2,0,2]),np.array(['Caliente','Frio']))","metadata":{"tags":[],"cell_id":"2bedf5620fa0437eab84ab764a8f3884","source_hash":"6813fb43","execution_start":1670941741956,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(0.012800000000000004, ['Origen', 'Caliente', 'Frio', 'Caliente'])"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"Modelo.baumwelch(np.array([2,0,2]))","metadata":{"tags":[],"cell_id":"01e647ff675649649bf5d32b8ab5bfa8","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=15d2711e-8488-4966-b405-4363c7f8973c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"cfca16eff36b4651bfd65d7bb446273d","deepnote_persisted_session":{"createdAt":"2022-12-13T15:24:15.765Z"},"deepnote_execution_queue":[]}}